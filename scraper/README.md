# Web Scraper - Requisitoriados Recompensas.pe

Sistema de web scraping para extraer informaci√≥n de requisitoriados desde https://recompensas.pe/requisitoriados

## üìã Caracter√≠sticas

- ‚úÖ B√∫squeda por nombre o apellido
- ‚úÖ Extracci√≥n de datos completos (nombre, foto, recompensa, estado, sexo, lugar de RO, delitos)
- ‚úÖ Descarga autom√°tica de fotos
- ‚úÖ Exportaci√≥n a JSON y CSV
- ‚úÖ Soporte para b√∫squedas m√∫ltiples
- ‚úÖ Manejo de errores y reintentos
- ‚úÖ Logs detallados del progreso
- ‚úÖ Esperas expl√≠citas para contenido din√°mico

## üöÄ Instalaci√≥n

### Requisitos previos

- Python 3.8 o superior
- pip (gestor de paquetes de Python)

### Pasos de instalaci√≥n

1. **Clonar o descargar el repositorio**

```bash
cd scraper
```

2. **Crear un entorno virtual (recomendado)**

```bash
python -m venv venv

# En Windows:
venv\Scripts\activate

# En Linux/Mac:
source venv/bin/activate
```

3. **Instalar dependencias**

```bash
pip install -r requirements.txt
```

4. **Instalar navegadores de Playwright**

```bash
playwright install chromium
```

## üìñ Uso

### Script de Ejecuci√≥n Autom√°tica

Para realizar una b√∫squeda autom√°tica de "william peter loayza mamani" con resultados formateados:

```bash
python run_search.py
```

Este script:
- ‚úÖ Ejecuta autom√°ticamente la b√∫squeda sin interacci√≥n del usuario
- ‚úÖ Muestra los resultados con formato visual y emojis
- ‚úÖ Exporta autom√°ticamente a JSON y CSV
- ‚úÖ Descarga las fotos de los requisitoriados
- ‚úÖ Muestra un resumen completo al finalizar

### Modo Interactivo

Ejecuta el script principal:

```bash
python scraper.py
```

El script te presentar√° dos opciones:

1. **B√∫squeda simple**: Buscar un solo nombre o apellido
2. **B√∫squedas m√∫ltiples**: Buscar varios nombres separados por comas

### Uso como M√≥dulo

Tambi√©n puedes importar y usar el scraper en tus propios scripts:

```python
from scraper import RequisitoriadosScraper

# Crear instancia
scraper = RequisitoriadosScraper()

# B√∫squeda simple
resultados = scraper.buscar_requisitoriado("LOAYZA")

# B√∫squedas m√∫ltiples
nombres = ["LOAYZA", "MAMANI", "GONZALES"]
todos_resultados = scraper.buscar_multiples(nombres)

# Exportar resultados
scraper.exportar_json("mis_resultados.json")
scraper.exportar_csv("mis_resultados.csv")
```

## üìÇ Estructura de Salida

```
/scraper
  /output
    - resultados.json       # Resultados en formato JSON
    - resultados.csv        # Resultados en formato CSV
    /fotos                  # Fotos descargadas de los requisitoriados
      - William_Peter_Loayza_Mamani.jpg
      - ...
```

## üìä Formato de Datos

### JSON

```json
[
  {
    "nombre_completo": "William Peter Loayza Mamani",
    "foto_url": "https://recompensas.pe/assets/images/...",
    "foto_local": "scraper/output/fotos/William_Peter_Loayza_Mamani.jpg",
    "recompensa": "S/ 20,000",
    "estado": "Requisitoriado",
    "sexo": "Masculino",
    "lugar_ro": "CUSCO - CUSCO",
    "delitos": "VIOLACI√ìN SEXUAL DE MENOR DE EDAD"
  }
]
```

### CSV

El archivo CSV contiene las mismas columnas que el JSON, separadas por comas.

## üîß Configuraci√≥n Avanzada

### Cambiar tiempo de espera

En el c√≥digo, puedes ajustar los timeouts:

```python
# En scraper.py, m√©todo buscar_requisitoriado
page.goto(self.BASE_URL, wait_until='networkidle', timeout=60000)  # 60 segundos
```

### Cambiar n√∫mero de reintentos

```python
resultados = scraper.buscar_requisitoriado("NOMBRE", max_retries=5)
```

### Modo headless

Por defecto, el navegador se ejecuta en modo headless (sin ventana visible). Para ver el navegador:

```python
# En scraper.py, l√≠nea ~202
browser = p.chromium.launch(headless=False)  # Cambiar a False
```

## üêõ Soluci√≥n de Problemas

### Error: "Playwright no encontrado"

```bash
pip install playwright
playwright install chromium
```

### Error: "No se encontraron resultados"

- Verifica que la p√°gina est√© accesible: https://recompensas.pe/requisitoriados
- Intenta con otro nombre o apellido m√°s com√∫n
- Revisa los logs para ver detalles del error

### Error: "Timeout"

- La p√°gina puede estar lenta, aumenta el timeout
- Verifica tu conexi√≥n a internet
- El sitio podr√≠a estar ca√≠do temporalmente

### Las fotos no se descargan

- Verifica que tengas acceso a internet
- Algunas URLs de im√°genes pueden estar rotas
- Revisa los logs para ver errores espec√≠ficos

## üìù Notas Importantes

- La p√°gina usa Angular, por lo que requiere esperas expl√≠citas
- El scraper implementa retry logic para manejar p√°ginas lentas
- Los resultados se guardan autom√°ticamente en la carpeta `output`
- Las fotos se descargan con nombres seguros (sin caracteres especiales)
- El scraper respeta la estructura de la p√°gina y no realiza acciones invasivas

## ‚öñÔ∏è Consideraciones Legales

- Este scraper es solo para fines educativos y de investigaci√≥n
- Respeta los t√©rminos de servicio del sitio web
- No hagas scraping masivo que pueda afectar el rendimiento del sitio
- La informaci√≥n extra√≠da es de dominio p√∫blico

## ü§ù Contribuciones

Si encuentras bugs o quieres mejorar el scraper:

1. Reporta el issue
2. Sugiere mejoras
3. Env√≠a un pull request

## üìÑ Licencia

Este proyecto es de c√≥digo abierto y est√° disponible para uso educativo.

## üìû Soporte

Si tienes problemas:

1. Revisa la secci√≥n de "Soluci√≥n de Problemas"
2. Verifica los logs del scraper
3. Abre un issue en el repositorio

---

**Versi√≥n**: 1.0.0  
**√öltima actualizaci√≥n**: 2025-10-14
